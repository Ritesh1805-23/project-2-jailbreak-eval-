# project-2-jailbreak-eval-
Prompt vulnerability testing of ChatGPT vs Claude using jailbreak prompts to evaluate safety, ethics, and response manipulation resistance.
